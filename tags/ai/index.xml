<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI on Robins Website</title>
    <link>http://localhost:1313/tags/ai/</link>
    <description>Recent content in AI on Robins Website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Jul 2024 15:30:05 -0700</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Making of Cat Gallery! Part 1</title>
      <link>http://localhost:1313/posts/cat_gallery/</link>
      <pubDate>Thu, 18 Jul 2024 15:30:05 -0700</pubDate>
      <guid>http://localhost:1313/posts/cat_gallery/</guid>
      <description>Motivation and Inspiration mimi and leo, my two cats. I love them. https://www.youtube.com/watch?v=GiaD7WSdb4M&amp;amp; Modern search engines aren&amp;rsquo;t very good at finding pictures (only via metadata) i think vision models are pretty cool Whats the basic idea? Have an API to do the search!&#xA;provided by the image server files live on the image server actually, the image server does all the computation The API is then called by a some static site.</description>
    </item>
    <item>
      <title>Running a Large Language Model on my School Supercomputer</title>
      <link>http://localhost:1313/posts/hpc_llm/</link>
      <pubDate>Wed, 22 May 2024 01:37:53 -0700</pubDate>
      <guid>http://localhost:1313/posts/hpc_llm/</guid>
      <description>Welcome! I was having some fun browsing /r/localLLaMA and I saw that llama3 popped up!&#xA;At the time it was real good for its parameter size and just in general, so I wanted to try to run it!&#xA;Of course, I could&amp;rsquo;ve ran it in a Q5 quantized form on my desktop with a 1080ti, however, I felt like using my school funding to use.</description>
    </item>
  </channel>
</rss>
